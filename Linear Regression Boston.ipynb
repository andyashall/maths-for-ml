{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import explained_variance_score\n",
    "import numpy as np\n",
    "\n",
    "x = load_boston().data\n",
    "y = load_boston().target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(379, 13)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=29)\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynom(m, deg):\n",
    "    n_rows, n_cols = m.shape[0], m.shape[1]\n",
    "    nm = np.zeros((m.shape[0],n_cols*deg))\n",
    "    for d in range(deg):\n",
    "        for c in range(n_cols):\n",
    "            for r in range(n_rows):\n",
    "                nm[r][n_cols*d+c] = m[r][c]**(d+1)\n",
    "    return nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling\n",
    "def scaling(X):\n",
    "    for c in range(X.shape[1]):\n",
    "        X[:,c] = [(i - np.mean(X[:,c])) / (max(X[:,c]) - min(X[:,c])) for i in X[:,c]]\n",
    "    return X\n",
    "\n",
    "# normalize\n",
    "def normal(X):\n",
    "    return X / X.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, theta):\n",
    "    return np.c_[np.ones(len(X)), normal(X)] @ theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 35.98189827  -6.88140442   5.31800698   1.01840583   3.43338847\n",
      " -12.89840309  31.08338357  -0.25493095 -16.56781587   7.73387839\n",
      "  -9.19866233 -21.23376392   4.39090559 -20.92958659]\n",
      "\n",
      "Norm Eq EVS: 0.717097886997718\n"
     ]
    }
   ],
   "source": [
    "def normalEq(X, y):\n",
    "    X = np.c_[np.ones(len(X)), normal(X)]\n",
    "    return (np.linalg.inv(X.T @ X) @ X.T @ y).T\n",
    "\n",
    "theta = normalEq(x_train, y_train)\n",
    "\n",
    "print(theta)\n",
    "\n",
    "preds = predict(x_test, theta)\n",
    "\n",
    "print(f'\\nNorm Eq EVS: {explained_variance_score(preds, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Norm Eq EVS: 0.7181512345558685\n"
     ]
    }
   ],
   "source": [
    "class Ridge:\n",
    "    def __init__(self, a):\n",
    "        self.a = a\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X = np.c_[np.ones(len(X)), normal(X)]\n",
    "        self.theta = (np.linalg.inv(X.T @ X + self.a * np.identity(1)) @ X.T @ y)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.c_[np.ones(len(X)), normal(X)] @ self.theta\n",
    "\n",
    "m = Ridge(10)\n",
    "\n",
    "m.fit(x_train, y_train)\n",
    "\n",
    "preds = m.predict(x_test)\n",
    "        \n",
    "# theta = RidgeEq(x_train, y_train, 0.1)\n",
    "\n",
    "# print(theta)\n",
    "\n",
    "# preds = predict(x_test, theta)\n",
    "\n",
    "print(f'\\nNorm Eq EVS: {explained_variance_score(preds, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$X^{'}X=\\begin{bmatrix} 7 & 38.5\\\\  38.5& 218.75 \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 21.48175763  -5.21052653   0.49326403  -2.29180405   1.8618664\n",
      "    1.24390193  12.11210382  -3.66071495  -9.05726146   6.44094765\n",
      "   -3.72503253  -1.54039884   6.20513171 -26.47508868  -1.76233164\n",
      "    4.44617089   4.0114199    1.64128015  -7.56912652  20.10511533\n",
      "    3.00061925  -2.81398974   0.1993134   -4.05174292  -9.73012564\n",
      "   -1.04832018  10.66914994]]\n",
      "\n",
      "BGD EVS: 0.7404059544112933\n"
     ]
    }
   ],
   "source": [
    "def BGD(X, y, n_iter, eta):\n",
    "    X = np.c_[np.ones(len(X)), normal(X)]\n",
    "    y = np.array([y.T])\n",
    "    theta = np.random.rand(1, X.shape[1])\n",
    "    for i in range(n_iter):\n",
    "        for c in range(X.shape[1]):\n",
    "            nX = X[:,c]\n",
    "            nT = theta[:,c]\n",
    "            gradients = ((X @ theta.T) - y.T).T @ nX\n",
    "            theta[:,c] = nT - eta * gradients\n",
    "    return theta.T\n",
    "\n",
    "theta = BGD(polynom(x_train, 2), y_train, 1000, 0.001)\n",
    "\n",
    "print(theta.T)\n",
    "\n",
    "preds = predict(polynom(x_test, 2), theta)\n",
    "\n",
    "print(f'\\nBGD EVS: {explained_variance_score(preds, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.24643147e+00  -3.29898102e+00   2.32214303e+00   2.92197089e+00\n",
      "    1.33970949e+00  -4.20696380e+00   2.53506742e+01  -5.99173023e+00\n",
      "   -5.57913969e+00   7.06379388e+00  -3.37520686e-03   5.32311689e+00\n",
      "    5.73467437e+00  -1.54072693e+01  -2.66497405e+00   4.23739371e+00\n",
      "    1.26171947e-01   1.22708776e+00  -5.23986648e+00   2.05447971e+01\n",
      "    7.34671249e+00  -3.14806413e+00   3.20087895e+00  -1.29556703e+01\n",
      "   -9.94858007e+00   5.21667687e-02   1.88069379e+00]]\n",
      "\n",
      "SGD EVS: 0.6928754526820999\n",
      "3.7555449999999997\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.clock()\n",
    "\n",
    "def learning_schedule(t):\n",
    "    return 5 / (t + 50)\n",
    "\n",
    "def SGD(X, y, n_epoch, eta):\n",
    "    X = np.c_[np.ones(len(X)), normal(X)]\n",
    "    y = np.array([y.T])\n",
    "    theta = np.random.rand(1, X.shape[1])\n",
    "    m = X.shape[0]\n",
    "    for epoch in range(1, n_epoch):\n",
    "        for n in range(m):\n",
    "            for c in range(X.shape[1]):\n",
    "                r = np.random.randint(0, m-1)\n",
    "                xi, yi = X[r:r+1], y.T[r:r+1]\n",
    "                gradients = ((xi @ theta.T) - yi.T).T @ xi[:,c]\n",
    "#                 eta = eta/epoch\n",
    "                theta[:,c] = theta[:,c] - (gradients * eta)\n",
    "    return theta.T\n",
    "\n",
    "theta = SGD(polynom(x_train, 2), y_train, 50, 0.01)\n",
    "\n",
    "print(theta.T)\n",
    "\n",
    "preds = predict(polynom(x_test, 2), theta)\n",
    "\n",
    "print(f'\\nSGD EVS: {explained_variance_score(preds, y_test)}')\n",
    "\n",
    "print(time.clock() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 36.90890086 -16.83969786  -3.86163523  -9.35246913   5.72236384\n",
      "    2.64044615  -3.10944942  -5.93332168 -17.31346032  10.91323228\n",
      "   -5.20743124   5.26539832  12.55465042 -55.50831314   8.34740545\n",
      "    7.34089644  10.82089486  -2.39204345 -10.31394287  23.92606408\n",
      "    5.94830668   4.89327161  -1.55528663  -3.25194018 -13.86446479\n",
      "   -7.52477399  38.84850446]]\n",
      "\n",
      " MBGD EVS: 0.7548311531412629\n",
      "0.5438309999999973\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.clock()\n",
    "\n",
    "def MBGD(X, y, n_epoch, batch_size, eta):\n",
    "    X = np.c_[np.ones(len(X)), normal(X)]\n",
    "    y = np.array([y.T])\n",
    "    theta = np.random.rand(1, X.shape[1])\n",
    "    m = X.shape[0]\n",
    "    for epoch in range(n_epoch):\n",
    "        shuffi = np.random.permutation(m)\n",
    "        xs, ys = X[shuffi], y.T[shuffi]\n",
    "        for i in range(0, m, batch_size):\n",
    "            for c in range(X.shape[1]):\n",
    "                xi, yi = X[i:i+batch_size], y.T[i:i+batch_size]\n",
    "                gradients = ((xi @ theta.T) - yi).T @ xi[:,c]\n",
    "                theta[:,c] = theta[:,c] - (gradients * eta)\n",
    "    return theta.T\n",
    "        \n",
    "theta = MBGD(polynom(x_train, 2), y_train, 500, 64, 0.01)\n",
    "\n",
    "print(theta.T)\n",
    "\n",
    "preds = predict(polynom(x_test, 2), theta)\n",
    "\n",
    "print(f'\\n MBGD EVS: {explained_variance_score(preds, y_test)}')\n",
    "\n",
    "print(time.clock() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 30.41618575 -12.55667436  -1.3485853   -1.73591433   2.87456095\n",
      "   14.42178196   9.72087653  -2.44594127 -14.62455899  10.61420675\n",
      "   -5.93581858  -9.48040865   5.094256   -47.91393294   4.20024488\n",
      "    6.10805002   3.50970284   0.47668857 -17.18621574  15.2040884\n",
      "    2.62020808   3.7896093   -2.64599867  -2.36364123  -5.63750186\n",
      "   -0.83820171  31.1940496 ]]\n",
      "\n",
      "Ridge Best EVS: 0.7409223943640557\n",
      "\n",
      "Ridge Last EVS: 0.7409223943640557\n"
     ]
    }
   ],
   "source": [
    "def Ridge(X, y, n_iter, eta, alpha):\n",
    "    X = np.c_[np.ones(len(X)), normal(X)]\n",
    "    y = np.array([y.T])\n",
    "    theta = np.random.rand(1, X.shape[1])\n",
    "    best = theta\n",
    "    for i in range(n_iter):\n",
    "        for c in range(X.shape[1]):\n",
    "            nX = X[:,c]\n",
    "            nT = theta[:,c]\n",
    "            gradients = (((X @ theta.T) - y.T).T @ nX) + 2 * alpha * theta[:,c]\n",
    "            theta[:,c] = nT - eta * gradients\n",
    "        b = explained_variance_score(X @ best.T, y.T)\n",
    "        c = explained_variance_score(X @ theta.T, y.T)\n",
    "        if c > b:\n",
    "            best = theta\n",
    "    return (best.T, theta.T)\n",
    "\n",
    "theta, l = Ridge(polynom(x_train, 2), y_train, 10000, 0.01, 0.1)\n",
    "\n",
    "print(theta.T)\n",
    "\n",
    "preds = predict(polynom(x_test, 2), theta)\n",
    "\n",
    "predsl = predict(polynom(x_test, 2), l)\n",
    "\n",
    "print(f'\\nRidge Best EVS: {explained_variance_score(preds, y_test)}')\n",
    "print(f'\\nRidge Last EVS: {explained_variance_score(predsl, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.08884746e+01  -5.14840774e+00   4.75692581e-01  -1.70879486e+00\n",
      "    1.78731340e+00   1.20804742e-03   1.22803641e+01  -2.77124626e+00\n",
      "   -8.77196132e+00   6.16238114e+00  -3.66365665e+00  -1.70155230e+00\n",
      "    5.79840315e+00  -2.57371678e+01  -1.17227021e+00   4.38311653e+00\n",
      "    3.30821586e+00   1.71327155e+00  -6.42050946e+00   2.02263920e+01\n",
      "    2.26221454e+00  -2.68663558e+00  -7.93849276e-03  -3.51672115e+00\n",
      "   -9.41384602e+00  -5.94744492e-01   9.91499675e+00]]\n",
      "\n",
      "LASSO EVS: 0.736123868444756\n"
     ]
    }
   ],
   "source": [
    "def LASSO(X, y, n_iter, eta, alpha):\n",
    "    X = np.c_[np.ones(len(X)), normal(X)]\n",
    "    y = np.array([y.T])\n",
    "    theta = np.random.rand(1, X.shape[1])\n",
    "    for i in range(n_iter):\n",
    "        for c in range(X.shape[1]):\n",
    "            nX = X[:,c]\n",
    "            nT = theta[:,c]\n",
    "            gradients = ((X @ theta.T) - y.T).T @ nX + alpha * np.sign(theta[:,c])\n",
    "            theta[:,c] = nT - eta * gradients\n",
    "    return theta.T\n",
    "\n",
    "theta = LASSO(polynom(x_train, 2), y_train, 1000, 0.001, 1)\n",
    "\n",
    "print(theta.T)\n",
    "\n",
    "preds = predict(polynom(x_test, 2), theta)\n",
    "\n",
    "print(f'\\nLASSO EVS: {explained_variance_score(preds, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "\n",
    "polybig_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "std_scaler = StandardScaler()\n",
    "lin_reg = LinearRegression()\n",
    "polynomial_regression = Pipeline([\n",
    "        (\"poly_features\", polybig_features),\n",
    "        (\"std_scaler\", std_scaler),\n",
    "        (\"lin_reg\", lin_reg),\n",
    "    ])\n",
    "polynomial_regression.fit(x_train, y_train)\n",
    "preds = polynomial_regression.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: \n",
      "[ -4.45795003e-01  -4.20281709e-02  -1.13638279e-01   1.26681724e+00\n",
      "  -1.43233686e+00  -2.18378528e+00  -3.29550428e-02  -1.37782981e+00\n",
      "   5.43332742e-01  -3.16984967e-02  -1.81378244e+00   2.67667275e-02\n",
      "  -1.80841526e+00   4.67544909e-03   7.78662251e-04   3.97695328e-03\n",
      "   1.26681724e+00  -1.98542113e+00   4.07584210e-01   3.40675265e-04\n",
      "   4.48095854e-02  -7.28036088e-03   2.27704613e-05   3.08977838e-02\n",
      "  -3.93823629e-05   3.58743805e-02]\n",
      "Intercept: \n",
      "66.143471914\n",
      "\n",
      " Scikit learn ridge reg EVS: 0.7704624730353917\n"
     ]
    }
   ],
   "source": [
    "m = Ridge(alpha = 10)\n",
    "\n",
    "m.fit(polynom(x_train, 2), y_train)\n",
    "\n",
    "preds = m.predict(polynom(x_test, 2))\n",
    "\n",
    "print('weights: ')\n",
    "print(m.coef_)\n",
    "print('Intercept: ')\n",
    "print(m.intercept_)\n",
    "\n",
    "print(f'\\n Scikit learn ridge reg EVS: {explained_variance_score(y_test, preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
