{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import explained_variance_score\n",
    "import numpy as np\n",
    "\n",
    "x = load_boston().data\n",
    "y = load_boston().target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(379, 13)"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=29)\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynom(m, deg):\n",
    "    n_rows, n_cols = m.shape[0], m.shape[1]\n",
    "    nm = np.zeros((m.shape[0],n_cols*deg))\n",
    "    for d in range(deg):\n",
    "        for c in range(n_cols):\n",
    "            for r in range(n_rows):\n",
    "                nm[r][n_cols*d+c] = m[r][c]**(d+1)\n",
    "    return nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-1. , -1. , -0.5, -0.5, -0.5],\n",
       "        [ 0. ,  0. , -0.5,  1. , -0.5],\n",
       "        [ 1. ,  1. ,  1. , -0.5,  1. ]])"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scaling\n",
    "def scaling(X):\n",
    "    for c in range(X.shape[1]):\n",
    "        X[:,c] = [(i - np.mean(X[:,c])) / (max(X[:,c]) - min(X[:,c])) for i in X[:,c]]\n",
    "    return X\n",
    "\n",
    "# normalize\n",
    "def normal(X):\n",
    "    return X / X.max(axis=0)\n",
    "\n",
    "normal(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, theta):\n",
    "    return np.c_[np.ones(len(X)), normal(X)] @ theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 22.61794195  -6.88081299   5.31800698   1.00151806   3.43338847\n",
      "  -7.19704237  18.47655796  -0.2396351  -15.02450125   7.41163346\n",
      "  -6.77932357  -9.07260822   4.38736543 -19.97598678]\n",
      "\n",
      "Norm Eq EVS: 0.7416264097926808\n"
     ]
    }
   ],
   "source": [
    "def normalEq(X, y):\n",
    "    X = np.c_[np.ones(len(X)), scaling(X)]\n",
    "    return (np.linalg.inv(X.T @ X) @ X.T @ y).T\n",
    "\n",
    "theta = normalEq(x_train, y_train)\n",
    "\n",
    "print(theta)\n",
    "\n",
    "preds = predict(x_test, theta)\n",
    "\n",
    "print(f'\\nNorm Eq EVS: {explained_variance_score(preds, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$X^{'}X=\\begin{bmatrix} 7 & 38.5\\\\  38.5& 218.75 \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 19.20634228]\n",
      " [ -9.2427743 ]\n",
      " [ -2.17089119]\n",
      " [  0.66995084]\n",
      " [  0.94126055]\n",
      " [ -5.02641502]\n",
      " [  5.73495914]\n",
      " [  0.60629257]\n",
      " [ -8.35755114]\n",
      " [  5.7156615 ]\n",
      " [ -4.16123053]\n",
      " [ -2.36057202]\n",
      " [  0.11475703]\n",
      " [-20.90252573]\n",
      " [ -0.87968749]\n",
      " [  5.11832911]\n",
      " [  2.25772547]\n",
      " [  2.21811194]\n",
      " [ -1.24343535]\n",
      " [ 13.15609598]\n",
      " [  2.53579219]\n",
      " [  2.55018273]\n",
      " [ -1.9074604 ]\n",
      " [  0.75192262]\n",
      " [  3.72083115]\n",
      " [ -2.47023228]\n",
      " [ 14.19620019]]\n",
      "\n",
      "BGD EVS: 0.8140623442564865\n"
     ]
    }
   ],
   "source": [
    "def BGD(X, y, n_iter, eta):\n",
    "    X = np.c_[np.ones(len(X)), normal(X)]\n",
    "    y = np.array([y.T])\n",
    "    theta = np.random.rand(1, X.shape[1])\n",
    "    for i in range(n_iter):\n",
    "        for c in range(X.shape[1]):\n",
    "            nX = X[:,c]\n",
    "            nT = theta[:,c]\n",
    "            gradients = ((X @ theta.T) - y.T).T @ nX\n",
    "            theta[:,c] = nT - eta * gradients\n",
    "    return theta.T\n",
    "\n",
    "theta = BGD(polynom(x_train, 2), y_train, 1000, 0.001)\n",
    "\n",
    "print(theta)\n",
    "\n",
    "preds = predict(polynom(x_test, 2), theta)\n",
    "\n",
    "print(f'\\nBGD EVS: {explained_variance_score(preds, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 18.83559704]\n",
      " [ -7.47011212]\n",
      " [ -1.08192989]\n",
      " [  0.22937703]\n",
      " [ -0.429755  ]\n",
      " [ -3.26909609]\n",
      " [  7.26167115]\n",
      " [  0.58524702]\n",
      " [ -6.9499567 ]\n",
      " [  4.96951045]\n",
      " [ -4.60556924]\n",
      " [ -2.29254982]\n",
      " [  0.33788698]\n",
      " [-18.3234577 ]\n",
      " [ -1.24059598]\n",
      " [  3.93647342]\n",
      " [  4.72796103]\n",
      " [  2.67272805]\n",
      " [ -2.46314802]\n",
      " [ 14.66677497]\n",
      " [  3.24139179]\n",
      " [  1.01073016]\n",
      " [ -0.2324581 ]\n",
      " [  0.08740002]\n",
      " [  2.30703379]\n",
      " [  0.11071134]\n",
      " [ 10.52767917]]\n",
      "\n",
      "SGD EVS: 0.827425550330545\n"
     ]
    }
   ],
   "source": [
    "def learning_schedule(t):\n",
    "    return 5 / (t + 50)\n",
    "\n",
    "def SGD(X, y, n_epoch, eta):\n",
    "    X = np.c_[np.ones(len(X)), normal(X)]\n",
    "    y = np.array([y.T])\n",
    "    theta = np.random.rand(1, X.shape[1])\n",
    "    m = X.shape[0]\n",
    "    for epoch in range(1, n_epoch):\n",
    "        for n in range(m):\n",
    "            for c in range(X.shape[1]):\n",
    "                r = np.random.randint(0, m-1)\n",
    "                xi, yi = X[r:r+1], y.T[r:r+1]\n",
    "                gradients = ((xi @ theta.T) - yi.T).T @ xi[:,c]\n",
    "#                 eta = eta/epoch\n",
    "                theta[:,c] = theta[:,c] - (gradients * eta)\n",
    "    return theta.T\n",
    "\n",
    "theta = SGD(polynom(x_train, 2), y_train, 50, 0.01)\n",
    "\n",
    "print(theta)\n",
    "\n",
    "preds = predict(polynom(x_test, 2), theta)\n",
    "\n",
    "print(f'\\nSGD EVS: {explained_variance_score(preds, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 22.53683872]\n",
      " [ -5.51904959]\n",
      " [ -3.4627349 ]\n",
      " [  0.83913856]\n",
      " [ -0.60705795]\n",
      " [ -7.93832232]\n",
      " [  6.66307182]\n",
      " [  0.75006893]\n",
      " [-10.00536549]\n",
      " [  9.5157487 ]\n",
      " [ -4.18323917]\n",
      " [ -1.45006426]\n",
      " [ -1.30930688]\n",
      " [-20.72920014]\n",
      " [ -6.27117239]\n",
      " [  7.10618789]\n",
      " [  3.14753082]\n",
      " [  3.70272644]\n",
      " [  0.41509772]\n",
      " [ 12.27888272]\n",
      " [  1.19565218]\n",
      " [  2.81536288]\n",
      " [ -6.93870558]\n",
      " [  0.26005536]\n",
      " [  5.20769191]\n",
      " [-24.5679934 ]\n",
      " [ 14.95062064]]\n",
      "\n",
      " MBGD EVS: 0.796540884604747\n"
     ]
    }
   ],
   "source": [
    "def MBGD(X, y, n_epoch, batch_size, eta):\n",
    "    X = np.c_[np.ones(len(X)), normal(X)]\n",
    "    y = np.array([y.T])\n",
    "    theta = np.random.rand(1, X.shape[1])\n",
    "    m = X.shape[0]\n",
    "    for epoch in range(n_epoch):\n",
    "        shuffi = np.random.permutation(m)\n",
    "        xs, ys = X[shuffi], y.T[shuffi]\n",
    "        for i in range(0, m, batch_size):\n",
    "            for c in range(X.shape[1]):\n",
    "                r = np.random.randint(0, m-1)\n",
    "                xi, yi = X[i:i+batch_size], y.T[i:i+batch_size]\n",
    "                gradients = ((xi @ theta.T) - yi).T @ xi[:,c]\n",
    "                theta[:,c] = theta[:,c] - (gradients * eta)\n",
    "    return theta.T\n",
    "        \n",
    "theta = MBGD(polynom(x_train, 2), y_train, 100, 20, 0.01)\n",
    "\n",
    "print(theta)\n",
    "\n",
    "preds = predict(polynom(x_test, 2), theta)\n",
    "\n",
    "print(f'\\n MBGD EVS: {explained_variance_score(preds, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "\n",
    "polybig_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "std_scaler = StandardScaler()\n",
    "lin_reg = LinearRegression()\n",
    "polynomial_regression = Pipeline([\n",
    "        (\"poly_features\", polybig_features),\n",
    "        (\"std_scaler\", std_scaler),\n",
    "        (\"lin_reg\", lin_reg),\n",
    "    ])\n",
    "polynomial_regression.fit(x_train, y_train)\n",
    "preds = polynomial_regression.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: \n",
      "[ -4.82353170e-01  -6.11811058e-02  -1.03006200e-01   1.52751036e+00\n",
      "  -2.66093614e+01  -1.72065010e+01  -5.67860772e-02  -2.20943742e+00\n",
      "   5.80765699e-01  -2.01868784e-02  -6.10801742e+00   2.14283984e-02\n",
      "  -1.54975811e+00   4.96884001e-03   8.07538384e-04   6.18487450e-03\n",
      "   1.52751037e+00   3.81582232e+00   1.54888132e+00   5.40426439e-04\n",
      "   1.03788287e-01  -4.23190591e-03   6.78223968e-06   1.49536968e-01\n",
      "  -3.09227294e-05   2.80283423e-02]\n",
      "Intercept: \n",
      "164.391664059\n",
      "Scikit learn lin reg EVS: 0.8153831306538188\n"
     ]
    }
   ],
   "source": [
    "m = LinearRegression()\n",
    "\n",
    "m.fit(polynom(x_train, 2), y_train)\n",
    "\n",
    "preds = m.predict(polynom(x_test, 2))\n",
    "\n",
    "print('weights: ')\n",
    "print(m.coef_)\n",
    "print('Intercept: ')\n",
    "print(m.intercept_)\n",
    "\n",
    "print(f'\\n Scikit learn lin reg EVS: {explained_variance_score(y_test, preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
