{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import explained_variance_score\n",
    "import numpy as np\n",
    "\n",
    "x = load_boston().data\n",
    "y = load_boston().target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(379, 13)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=29)\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynom(m, deg):\n",
    "    n_rows, n_cols = m.shape[0], m.shape[1]\n",
    "    nm = np.zeros((m.shape[0],n_cols*deg))\n",
    "    for d in range(deg):\n",
    "        for c in range(n_cols):\n",
    "            for r in range(n_rows):\n",
    "                nm[r][n_cols*d+c] = m[r][c]**(d+1)\n",
    "    return nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling\n",
    "def scaling(X):\n",
    "    for c in range(X.shape[1]):\n",
    "        X[:,c] = [(i - np.mean(X[:,c])) / (max(X[:,c]) - min(X[:,c])) for i in X[:,c]]\n",
    "    return X\n",
    "\n",
    "# normalize\n",
    "def normal(X):\n",
    "    return X / X.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, theta):\n",
    "    return np.c_[np.ones(len(X)), normal(X)] @ theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 35.98189827  -6.88140442   5.31800698   1.01840583   3.43338847\n",
      " -12.89840309  31.08338357  -0.25493095 -16.56781587   7.73387839\n",
      "  -9.19866233 -21.23376392   4.39090559 -20.92958659]\n",
      "\n",
      "Norm Eq EVS: 0.717097886997718\n"
     ]
    }
   ],
   "source": [
    "def normalEq(X, y):\n",
    "    X = np.c_[np.ones(len(X)), normal(X)]\n",
    "    return (np.linalg.inv(X.T @ X) @ X.T @ y).T\n",
    "\n",
    "theta = normalEq(x_train, y_train)\n",
    "\n",
    "print(theta)\n",
    "\n",
    "preds = predict(x_test, theta)\n",
    "\n",
    "print(f'\\nNorm Eq EVS: {explained_variance_score(preds, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$X^{'}X=\\begin{bmatrix} 7 & 38.5\\\\  38.5& 218.75 \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.20223782e+01  -5.19784076e+00   4.83770305e-01  -2.59776506e+00\n",
      "    2.12002088e+00   1.24695326e+00   1.14681504e+01  -3.91248137e+00\n",
      "   -8.95968720e+00   6.67506125e+00  -4.10215510e+00  -1.84776717e+00\n",
      "    6.27458933e+00  -2.62575013e+01  -1.77267044e+00   4.43135725e+00\n",
      "    4.29923131e+00   1.39102456e+00  -7.58538291e+00   2.04871472e+01\n",
      "    3.20466708e+00  -2.94885416e+00   6.09839535e-03  -3.75989400e+00\n",
      "   -9.55363975e+00  -1.12117842e+00   1.04071540e+01]]\n",
      "\n",
      "BGD EVS: 0.7411088254882143\n"
     ]
    }
   ],
   "source": [
    "def BGD(X, y, n_iter, eta):\n",
    "    X = np.c_[np.ones(len(X)), normal(X)]\n",
    "    y = np.array([y.T])\n",
    "    theta = np.random.rand(1, X.shape[1])\n",
    "    for i in range(n_iter):\n",
    "        for c in range(X.shape[1]):\n",
    "            nX = X[:,c]\n",
    "            nT = theta[:,c]\n",
    "            gradients = ((X @ theta.T) - y.T).T @ nX\n",
    "            theta[:,c] = nT - eta * gradients\n",
    "    return theta.T\n",
    "\n",
    "theta = BGD(polynom(x_train, 2), y_train, 1000, 0.001)\n",
    "\n",
    "print(theta.T)\n",
    "\n",
    "preds = predict(polynom(x_test, 2), theta)\n",
    "\n",
    "print(f'\\nBGD EVS: {explained_variance_score(preds, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4.18379233  -3.71860706   3.821575     2.00446984   1.15910126\n",
      "    4.75921166  16.92737301   6.18395939  -3.80336233  -0.55577738\n",
      "   -1.08128133   4.28690803  13.50923699 -19.96798789  -0.93936281\n",
      "    1.38009989   0.62542377   2.48007316  -6.75509392  19.43180909\n",
      "   -5.18424831  -4.78353346   5.70475352  -4.88503682 -12.04338514\n",
      "   -6.53109802   3.77022403]]\n",
      "\n",
      "SGD EVS: 0.6933477276102831\n",
      "3.8847449999999952\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.clock()\n",
    "\n",
    "def learning_schedule(t):\n",
    "    return 5 / (t + 50)\n",
    "\n",
    "def SGD(X, y, n_epoch, eta):\n",
    "    X = np.c_[np.ones(len(X)), normal(X)]\n",
    "    y = np.array([y.T])\n",
    "    theta = np.random.rand(1, X.shape[1])\n",
    "    m = X.shape[0]\n",
    "    for epoch in range(1, n_epoch):\n",
    "        for n in range(m):\n",
    "            for c in range(X.shape[1]):\n",
    "                r = np.random.randint(0, m-1)\n",
    "                xi, yi = X[r:r+1], y.T[r:r+1]\n",
    "                gradients = ((xi @ theta.T) - yi.T).T @ xi[:,c]\n",
    "#                 eta = eta/epoch\n",
    "                theta[:,c] = theta[:,c] - (gradients * eta)\n",
    "    return theta.T\n",
    "\n",
    "theta = SGD(polynom(x_train, 2), y_train, 50, 0.01)\n",
    "\n",
    "print(theta.T)\n",
    "\n",
    "preds = predict(polynom(x_test, 2), theta)\n",
    "\n",
    "print(f'\\nSGD EVS: {explained_variance_score(preds, y_test)}')\n",
    "\n",
    "print(time.clock() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 36.87369548 -16.80812274  -3.88168439  -9.38996353   5.99668675\n",
      "    2.86621843  -3.09339067  -5.8625074  -17.20407428  11.00759676\n",
      "   -5.17865601   5.06277094  12.53436256 -55.61069993   8.31489337\n",
      "    7.37282102  10.87291703  -2.66597745 -10.44962978  23.88801476\n",
      "    5.89182077   4.79976558  -1.6356173   -3.27706993 -13.73666378\n",
      "   -7.50788395  38.95108533]]\n",
      "\n",
      " MBGD EVS: 0.7546838158863626\n",
      "0.5968079999999958\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.clock()\n",
    "\n",
    "def MBGD(X, y, n_epoch, batch_size, eta):\n",
    "    X = np.c_[np.ones(len(X)), normal(X)]\n",
    "    y = np.array([y.T])\n",
    "    theta = np.random.rand(1, X.shape[1])\n",
    "    m = X.shape[0]\n",
    "    for epoch in range(n_epoch):\n",
    "        shuffi = np.random.permutation(m)\n",
    "        xs, ys = X[shuffi], y.T[shuffi]\n",
    "        for i in range(0, m, batch_size):\n",
    "            for c in range(X.shape[1]):\n",
    "                xi, yi = X[i:i+batch_size], y.T[i:i+batch_size]\n",
    "                gradients = ((xi @ theta.T) - yi).T @ xi[:,c]\n",
    "                theta[:,c] = theta[:,c] - (gradients * eta)\n",
    "    return theta.T\n",
    "        \n",
    "theta = MBGD(polynom(x_train, 2), y_train, 500, 64, 0.01)\n",
    "\n",
    "print(theta.T)\n",
    "\n",
    "preds = predict(polynom(x_test, 2), theta)\n",
    "\n",
    "print(f'\\n MBGD EVS: {explained_variance_score(preds, y_test)}')\n",
    "\n",
    "print(time.clock() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379\n",
      "[[ 176.48982185 -178.22074539 -102.15676631  -68.87898967  -95.04262229\n",
      "   -17.26581437   -2.80856175   -6.00922379 -127.75400668  -13.07464471\n",
      "    22.39615007   39.12121671    2.20626544  -95.3582948  -217.35031848\n",
      "  -137.19599997 -113.2261404  -100.92324824  -67.33013198  -44.84284871\n",
      "     7.93134902 -175.12746477  -27.16227836  -12.07985465   19.11162755\n",
      "    34.88942765 -138.19320119]]\n",
      "\n",
      " Ridge EVS: 0.055707698338447686\n"
     ]
    }
   ],
   "source": [
    "import numpy.linalg as LA\n",
    "\n",
    "def Ridge(X, y, n_epoch, batch_size, alpha):\n",
    "    X = np.c_[np.ones(len(X)), normal(X)]\n",
    "    y = np.array([y.T])\n",
    "    theta = np.random.rand(1, X.shape[1])\n",
    "    m = X.shape[0]\n",
    "    print(m)\n",
    "    for epoch in range(n_epoch):\n",
    "        shuffi = np.random.permutation(m)\n",
    "        xs, ys = X[shuffi], y.T[shuffi]\n",
    "        for i in range(0, m, batch_size):\n",
    "            for c in range(X.shape[1]):\n",
    "                r = np.random.randint(0, m-1)\n",
    "                xi, yi = X[i:i+batch_size], y.T[i:i+batch_size]\n",
    "                gradients = ((xi @ theta.T) - yi).T @ xi[:,c]\n",
    "                theta[:,c] = theta[:,c] - alpha * (gradients + (alpha * LA.norm(theta)**2))\n",
    "    return theta.T\n",
    "\n",
    "theta = Ridge(polynom(x_train, 2), y_train, 50, 64, 0.01)\n",
    "\n",
    "print(theta.T)\n",
    "\n",
    "preds = predict(polynom(x_test, 2), theta)\n",
    "\n",
    "print(f'\\n Ridge EVS: {explained_variance_score(preds, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "\n",
    "polybig_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "std_scaler = StandardScaler()\n",
    "lin_reg = LinearRegression()\n",
    "polynomial_regression = Pipeline([\n",
    "        (\"poly_features\", polybig_features),\n",
    "        (\"std_scaler\", std_scaler),\n",
    "        (\"lin_reg\", lin_reg),\n",
    "    ])\n",
    "polynomial_regression.fit(x_train, y_train)\n",
    "preds = polynomial_regression.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: \n",
      "[ -4.45795003e-01  -4.20281709e-02  -1.13638279e-01   1.26681724e+00\n",
      "  -1.43233686e+00  -2.18378528e+00  -3.29550428e-02  -1.37782981e+00\n",
      "   5.43332742e-01  -3.16984967e-02  -1.81378244e+00   2.67667275e-02\n",
      "  -1.80841526e+00   4.67544909e-03   7.78662251e-04   3.97695328e-03\n",
      "   1.26681724e+00  -1.98542113e+00   4.07584210e-01   3.40675265e-04\n",
      "   4.48095854e-02  -7.28036088e-03   2.27704613e-05   3.08977838e-02\n",
      "  -3.93823629e-05   3.58743805e-02]\n",
      "Intercept: \n",
      "66.143471914\n",
      "\n",
      " Scikit learn ridge reg EVS: 0.7704624730353917\n"
     ]
    }
   ],
   "source": [
    "m = Ridge(alpha = 10)\n",
    "\n",
    "m.fit(polynom(x_train, 2), y_train)\n",
    "\n",
    "preds = m.predict(polynom(x_test, 2))\n",
    "\n",
    "print('weights: ')\n",
    "print(m.coef_)\n",
    "print('Intercept: ')\n",
    "print(m.intercept_)\n",
    "\n",
    "print(f'\\n Scikit learn ridge reg EVS: {explained_variance_score(y_test, preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
