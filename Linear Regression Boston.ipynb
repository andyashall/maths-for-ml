{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import explained_variance_score\n",
    "import numpy as np\n",
    "\n",
    "x = load_boston().data\n",
    "y = load_boston().target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(379, 13)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=29)\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynom(m, deg):\n",
    "    n_rows, n_cols = m.shape[0], m.shape[1]\n",
    "    nm = np.zeros((m.shape[0],n_cols*deg))\n",
    "    for d in range(deg):\n",
    "        for c in range(n_cols):\n",
    "            for r in range(n_rows):\n",
    "                nm[r][n_cols*d+c] = m[r][c]**(d+1)\n",
    "    return nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling\n",
    "def scaling(X):\n",
    "    for c in range(X.shape[1]):\n",
    "        X[:,c] = [(i - np.mean(X[:,c])) / (max(X[:,c]) - min(X[:,c])) for i in X[:,c]]\n",
    "    return X\n",
    "\n",
    "# normalize\n",
    "def normal(X):\n",
    "    return X / X.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, theta):\n",
    "    return np.c_[np.ones(len(X)), normal(X)] @ theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 35.98189827  -6.88140442   5.31800698   1.01840583   3.43338847\n",
      " -12.89840309  31.08338357  -0.25493095 -16.56781587   7.73387839\n",
      "  -9.19866233 -21.23376392   4.39090559 -20.92958659]\n",
      "\n",
      "Norm Eq EVS: 0.717097886997718\n"
     ]
    }
   ],
   "source": [
    "def normalEq(X, y):\n",
    "    X = np.c_[np.ones(len(X)), normal(X)]\n",
    "    return (np.linalg.inv(X.T @ X) @ X.T @ y).T\n",
    "\n",
    "theta = normalEq(x_train, y_train)\n",
    "\n",
    "print(theta)\n",
    "\n",
    "preds = predict(x_test, theta)\n",
    "\n",
    "print(f'\\nNorm Eq EVS: {explained_variance_score(preds, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$X^{'}X=\\begin{bmatrix} 7 & 38.5\\\\  38.5& 218.75 \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 21.8931335 ]\n",
      " [ -5.43487448]\n",
      " [  0.39796692]\n",
      " [ -2.42543318]\n",
      " [  1.89296495]\n",
      " [  0.72446924]\n",
      " [ 12.31921992]\n",
      " [ -3.8861149 ]\n",
      " [ -9.21228673]\n",
      " [  6.66478731]\n",
      " [ -3.68334728]\n",
      " [ -2.10035867]\n",
      " [  6.26678892]\n",
      " [-26.30110318]\n",
      " [ -1.50203824]\n",
      " [  4.53380238]\n",
      " [  4.13137407]\n",
      " [  1.61333946]\n",
      " [ -7.28443507]\n",
      " [ 19.95960147]\n",
      " [  3.17775833]\n",
      " [ -2.71401281]\n",
      " [  0.06367914]\n",
      " [ -4.11859494]\n",
      " [ -9.39385649]\n",
      " [ -1.10433132]\n",
      " [ 10.49937459]]\n",
      "\n",
      "BGD EVS: 0.7402080039764631\n"
     ]
    }
   ],
   "source": [
    "def BGD(X, y, n_iter, eta):\n",
    "    X = np.c_[np.ones(len(X)), normal(X)]\n",
    "    y = np.array([y.T])\n",
    "    theta = np.random.rand(1, X.shape[1])\n",
    "    for i in range(n_iter):\n",
    "        for c in range(X.shape[1]):\n",
    "            nX = X[:,c]\n",
    "            nT = theta[:,c]\n",
    "            gradients = ((X @ theta.T) - y.T).T @ nX\n",
    "            theta[:,c] = nT - eta * gradients\n",
    "    return theta.T\n",
    "\n",
    "theta = BGD(polynom(x_train, 2), y_train, 1000, 0.001)\n",
    "\n",
    "print(theta)\n",
    "\n",
    "preds = predict(polynom(x_test, 2), theta)\n",
    "\n",
    "print(f'\\nBGD EVS: {explained_variance_score(preds, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  8.13744458]\n",
      " [ -1.49712867]\n",
      " [  2.03728367]\n",
      " [ -0.49084929]\n",
      " [  4.40733603]\n",
      " [  8.95151053]\n",
      " [ 22.15881621]\n",
      " [  8.03065796]\n",
      " [ -6.49531498]\n",
      " [  2.02944954]\n",
      " [ -4.78797264]\n",
      " [  0.87613155]\n",
      " [  9.02382867]\n",
      " [-16.98927621]\n",
      " [ -2.16044495]\n",
      " [  3.77697549]\n",
      " [  1.80657927]\n",
      " [ -1.33602727]\n",
      " [ -9.57735991]\n",
      " [ 13.93369507]\n",
      " [ -7.33688433]\n",
      " [ -4.55990506]\n",
      " [  5.9088325 ]\n",
      " [ -5.74020734]\n",
      " [-13.52924355]\n",
      " [ -1.30876696]\n",
      " [  1.38733344]]\n",
      "\n",
      "SGD EVS: 0.7162274658139319\n",
      "4.337443999999998\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.clock()\n",
    "\n",
    "def learning_schedule(t):\n",
    "    return 5 / (t + 50)\n",
    "\n",
    "def SGD(X, y, n_epoch, eta):\n",
    "    X = np.c_[np.ones(len(X)), normal(X)]\n",
    "    y = np.array([y.T])\n",
    "    theta = np.random.rand(1, X.shape[1])\n",
    "    m = X.shape[0]\n",
    "    for epoch in range(1, n_epoch):\n",
    "        for n in range(m):\n",
    "            for c in range(X.shape[1]):\n",
    "                r = np.random.randint(0, m-1)\n",
    "                xi, yi = X[r:r+1], y.T[r:r+1]\n",
    "                gradients = ((xi @ theta.T) - yi.T).T @ xi[:,c]\n",
    "#                 eta = eta/epoch\n",
    "                theta[:,c] = theta[:,c] - (gradients * eta)\n",
    "    return theta.T\n",
    "\n",
    "theta = SGD(polynom(x_train, 2), y_train, 50, 0.01)\n",
    "\n",
    "print(theta)\n",
    "\n",
    "preds = predict(polynom(x_test, 2), theta)\n",
    "\n",
    "print(f'\\nSGD EVS: {explained_variance_score(preds, y_test)}')\n",
    "\n",
    "print(time.clock() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 37.04309579]\n",
      " [-16.75859051]\n",
      " [ -3.89250989]\n",
      " [ -9.40240935]\n",
      " [  5.93247627]\n",
      " [  2.56530559]\n",
      " [ -3.35917434]\n",
      " [ -5.92062448]\n",
      " [-17.38539747]\n",
      " [ 11.06770553]\n",
      " [ -5.32112355]\n",
      " [  5.24106173]\n",
      " [ 12.54123495]\n",
      " [-55.40492418]\n",
      " [  8.26405065]\n",
      " [  7.37683227]\n",
      " [ 10.86916509]\n",
      " [ -2.60188315]\n",
      " [-10.2671643 ]\n",
      " [ 24.10659902]\n",
      " [  5.92829214]\n",
      " [  4.96700177]\n",
      " [ -1.7045288 ]\n",
      " [ -3.15393348]\n",
      " [-13.84472861]\n",
      " [ -7.51091762]\n",
      " [ 38.73947415]]\n",
      "\n",
      " MBGD EVS: 0.755299048453566\n",
      "0.45688099999999565\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.clock()\n",
    "\n",
    "def MBGD(X, y, n_epoch, batch_size, eta):\n",
    "    X = np.c_[np.ones(len(X)), normal(X)]\n",
    "    y = np.array([y.T])\n",
    "    theta = np.random.rand(1, X.shape[1])\n",
    "    m = X.shape[0]\n",
    "    for epoch in range(n_epoch):\n",
    "        shuffi = np.random.permutation(m)\n",
    "        xs, ys = X[shuffi], y.T[shuffi]\n",
    "        for i in range(0, m, batch_size):\n",
    "            for c in range(X.shape[1]):\n",
    "                xi, yi = X[i:i+batch_size], y.T[i:i+batch_size]\n",
    "                gradients = ((xi @ theta.T) - yi).T @ xi[:,c]\n",
    "                theta[:,c] = theta[:,c] - (gradients * eta)\n",
    "    return theta.T\n",
    "        \n",
    "theta = MBGD(polynom(x_train, 2), y_train, 500, 64, 0.01)\n",
    "\n",
    "print(theta)\n",
    "\n",
    "preds = predict(polynom(x_test, 2), theta)\n",
    "\n",
    "print(f'\\n MBGD EVS: {explained_variance_score(preds, y_test)}')\n",
    "\n",
    "print(time.clock() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379\n",
      "[[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kkgh070/anaconda3/envs/porto/lib/python3.6/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in add\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-8b7695169d9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolynom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\n Ridge EVS: {explained_variance_score(preds, y_test)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/porto/lib/python3.6/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36mexplained_variance_score\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    409\u001b[0m     \"\"\"\n\u001b[1;32m    410\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 411\u001b[0;31m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0my_diff_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/porto/lib/python3.6/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \"\"\"\n\u001b[1;32m     75\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/porto/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    420\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    421\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/porto/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     41\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     42\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 43\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "import numpy.linalg as LA\n",
    "\n",
    "def Ridge(X, y, n_epoch, batch_size, eta, alpha):\n",
    "    X = np.c_[np.ones(len(X)), normal(X)]\n",
    "    y = np.array([y.T])\n",
    "    theta = np.random.rand(1, X.shape[1])\n",
    "    m = X.shape[0]\n",
    "    print(m)\n",
    "    for epoch in range(n_epoch):\n",
    "        shuffi = np.random.permutation(m)\n",
    "        xs, ys = X[shuffi], y.T[shuffi]\n",
    "        for i in range(0, m, batch_size):\n",
    "            for c in range(X.shape[1]):\n",
    "                r = np.random.randint(0, m-1)\n",
    "                xi, yi = X[i:i+batch_size], y.T[i:i+batch_size]\n",
    "                gradients = ((xi @ theta.T) - yi).T @ xi[:,c]\n",
    "                theta[:,c] = theta[:,c] - eta * (gradients + (alpha * LA.norm(theta)**2))\n",
    "    return theta.T\n",
    "\n",
    "theta = Ridge(polynom(x_train, 2), y_train, 50, 64, 0.01, 1.0)\n",
    "\n",
    "print(theta)\n",
    "\n",
    "preds = predict(polynom(x_test, 2), theta)\n",
    "\n",
    "print(f'\\n Ridge EVS: {explained_variance_score(preds, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "\n",
    "polybig_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "std_scaler = StandardScaler()\n",
    "lin_reg = LinearRegression()\n",
    "polynomial_regression = Pipeline([\n",
    "        (\"poly_features\", polybig_features),\n",
    "        (\"std_scaler\", std_scaler),\n",
    "        (\"lin_reg\", lin_reg),\n",
    "    ])\n",
    "polynomial_regression.fit(x_train, y_train)\n",
    "preds = polynomial_regression.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: \n",
      "[ -4.45795003e-01  -4.20281709e-02  -1.13638279e-01   1.26681724e+00\n",
      "  -1.43233686e+00  -2.18378528e+00  -3.29550428e-02  -1.37782981e+00\n",
      "   5.43332742e-01  -3.16984967e-02  -1.81378244e+00   2.67667275e-02\n",
      "  -1.80841526e+00   4.67544909e-03   7.78662251e-04   3.97695328e-03\n",
      "   1.26681724e+00  -1.98542113e+00   4.07584210e-01   3.40675265e-04\n",
      "   4.48095854e-02  -7.28036088e-03   2.27704613e-05   3.08977838e-02\n",
      "  -3.93823629e-05   3.58743805e-02]\n",
      "Intercept: \n",
      "66.143471914\n",
      "\n",
      " Scikit learn lin reg EVS: 0.7704624730353917\n"
     ]
    }
   ],
   "source": [
    "m = Ridge(alpha = 10)\n",
    "\n",
    "m.fit(polynom(x_train, 2), y_train)\n",
    "\n",
    "preds = m.predict(polynom(x_test, 2))\n",
    "\n",
    "print('weights: ')\n",
    "print(m.coef_)\n",
    "print('Intercept: ')\n",
    "print(m.intercept_)\n",
    "\n",
    "print(f'\\n Scikit learn lin reg EVS: {explained_variance_score(y_test, preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
